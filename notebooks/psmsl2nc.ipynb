{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import re\n",
    "\n",
    "\n",
    "import netCDF4\n",
    "import pandas\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def df2nc(df, filename, attributes=None, prefix=\"\", mode='w', standard_names=None, units=None):\n",
    "    if attributes is None:\n",
    "        attributes = {}\n",
    "    if units is None:\n",
    "        units = {}\n",
    "    if standard_names is None:\n",
    "        standard_names = {}\n",
    "    nc = netCDF4.Dataset(filename, mode)\n",
    "\n",
    "    ## ADD DIMENSIONS\n",
    "    records_dim = nc.createDimension(prefix + 'records', len(df))\n",
    "\n",
    "    ## ADD GLOBAL ATTRIBUTES\n",
    "    # see http://www.unidata.ucar.edu/software/thredds/current/netcdf-java/formats/DataDiscoveryAttConvention.html\n",
    "\n",
    "    for key, val in attributes.items():\n",
    "        setattr(nc, key, val)\n",
    "\n",
    "    ## ADD VARIABLES\n",
    "    for name, column in df.iteritems():\n",
    "        assert isinstance(column, pandas.core.series.Series), \"expected to iterate over columns\"\n",
    "        if column.dtype.char == 'O':\n",
    "            # try and cast to strong\n",
    "            column = column.astype('S')\n",
    "        # no longs in opendap\n",
    "        if column.dtype.char == 'l':\n",
    "            column = column.astype('int32')\n",
    "        var = nc.createVariable(prefix + name, column.dtype.str, (prefix + 'records', ))\n",
    "        var.long_name = name\n",
    "        if name in units:\n",
    "            var.units = units[name]\n",
    "        if name in standard_names:\n",
    "            var.standard_name = standard_names[name]\n",
    "            \n",
    "            \n",
    "        var[:] = np.asarray(column)\n",
    "\n",
    "    nc.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "%   METADATA FIELDS\n",
    "%   id                PSMSL id of station\n",
    "%   latitude          Latitude of station\n",
    "%   longitude         Longitude of station\n",
    "%   name              Name of station\n",
    "%   coastline         Old coastline code of station\n",
    "%   stationcode       Old stationcode of station\n",
    "%       (So, coastline/stationcode is the old PSMSL id of the station)\n",
    "%   stationflag       Is entire station flagged for attention? True\n",
    "%                       indicates yes: refer to station documentation for\n",
    "%                       further information\n",
    "\"\"\"\n",
    "metadata_fields = ['id', 'latitude', 'longitude', 'name', 'coastline', 'stationcode', 'stationflag']\n",
    "dtypes = {\n",
    "    \"id\": int,\n",
    "    \"latitude\": float,\n",
    "    \"longitude\": float,\n",
    "    \"name\": str,\n",
    "    \"coastline\": int,\n",
    "    \"stationcode\": int,\n",
    "    \"stationflag\": str\n",
    "}\n",
    "converters = {\n",
    "    \"name\": lambda x: x.strip()\n",
    "}\n",
    "stations = pandas.read_csv('../data/psmsl/rlr_annual/filelist.txt', sep=';', \n",
    "                     names=metadata_fields, dtype=dtypes,\n",
    "                    converters=converters)\n",
    "attributes = {\n",
    "    \"Conventions\": 'CF-1.6',\n",
    "    \"Metadata_Conventions\": 'Unidata Dataset Discovery v1.0',\n",
    "    \"standard_name_vocabulary\": 'CF-1.6',\n",
    "    \"title\": 'PSMSL Tide Gauge Dataset',\n",
    "    \"summary\": '',\n",
    "    \"source\": 'http://www.psmsl.org/data/',\n",
    "    \"uuid\": '97110a34-ae15-11e5-868e-3c15c2d29372',\n",
    "    \"id\": '',\n",
    "    \"institution\": 'Deltares',\n",
    "    \"creator_name\": 'Fedor Baart',\n",
    "    \"creator_url\": 'https://www.linkedin.com/in/fedorbaart',\n",
    "    \"creator_email\": 'fedor.baart@deltares.nl',\n",
    "    \"date_created\": '2015-12-29T10:11Z',\n",
    "    \"date_modified\": '2015-12-29T10:11Z',\n",
    "    \"date_issued\": '2015-12-29T10:11Z',\n",
    "    \"publisher_name\": 'PSMSL',\n",
    "    \"publisher_email\": 'psmsl@noc.ac.uk',\n",
    "    \"publisher_url\": 'http://www.psmsl.org/',\n",
    "    \"history\": 'Created n %s' % (datetime.datetime.now(),),\n",
    "    \"references\": 'http://www.jstor.org/stable/4299170',\n",
    "    \"license\": 'Undefined'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = '../data/catalogue.dat'\n",
    "lines = open(filename).readlines()\n",
    "gloss_pattern = re.compile(r'GLOSS\\s*(?P<gloss>\\d+)')\n",
    "station_id_pattern = re.compile(r'STATION ID\\s*:\\s*(?P<station_id>\\d+)')\n",
    "station_gloss = {}\n",
    "for i, line in enumerate(lines):\n",
    "    gloss_match = gloss_pattern.search(line)\n",
    "    if gloss_match:\n",
    "        station_id_match = station_id_pattern.search(lines[i+1])\n",
    "        if station_id_match:\n",
    "            gloss = int(gloss_match.group('gloss'))\n",
    "            station = int(station_id_match.group('station_id'))\n",
    "            station_gloss[station] = gloss\n",
    "        else:\n",
    "            raise ValueError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = '../data/psmsl/metadata.nc'\n",
    "df2nc(stations, filename, attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def store_station(station):\n",
    "    \"\"\"\n",
    "    %   DATA FIELDS\n",
    "    %   year              Year of data\n",
    "    %   height            Annual height relative to RLR, in millimetres\n",
    "    %                       NaN indicates that data is missing\n",
    "    %   interpolated      Does the value include large amounts of\n",
    "    %                       inferred data (see PSMSL help file for information)\n",
    "    %   dataflag          Quality control flag - true values indicate problems\n",
    "    %                       with the data - see station documentation for\n",
    "    %                       further information\n",
    "    \"\"\"\n",
    "    ncfile = '../data/psmsl/station_%d.nc' % (station.id)\n",
    "\n",
    "    station['gloss_id'] = str(station_gloss.get(station.id))\n",
    "\n",
    "    station_attributes = attributes.copy()\n",
    "    station_attributes.update(station.to_dict())\n",
    "    # name is not updated\n",
    "    station_attributes['station_name'] = station['name']\n",
    "\n",
    "    units = {'latitude': 'degrees_north', 'longitude': 'degreas_east'}\n",
    "    standard_names = {'longitude': 'longitude', 'latitude': 'latitude'}\n",
    "\n",
    "    df = pandas.DataFrame.from_records([station])\n",
    "    \n",
    "    df2nc(df, ncfile, attributes=station_attributes, prefix=\"\", mode='w', units=units, standard_names=standard_names)\n",
    "\n",
    "    names = names=('year', 'height', 'interpolated', 'dataflag')\n",
    "    na_values = {\"height\": [-99999]}\n",
    "    units = {'height': 'm'}\n",
    "    standard_names = {'height': 'sea_surface_height'}\n",
    "\n",
    "    filename = \"../data/psmsl/rlr_annual/data/%d.rlrdata\" % (station.id,)\n",
    "    df = pandas.read_csv(filename, sep=';', names=names, na_values=na_values)\n",
    "    df2nc(df, ncfile, prefix=\"annual_\", mode='a', units=units, standard_names=standard_names)\n",
    "\n",
    "    filename = \"../data/psmsl/rlr_monthly/data/%d.rlrdata\" % (station.id,)\n",
    "    df = pandas.read_csv(filename, sep=';', names=names, na_values=na_values)\n",
    "    df2nc(df, ncfile, prefix=\"monthly_\", mode='a', units=units, standard_names=standard_names)\n",
    "\n",
    "    filename = \"../data/psmsl/met_monthly/data/%d.metdata\" % (station.id,)\n",
    "    df = pandas.read_csv(filename, sep=';', names=names, na_values=na_values)\n",
    "    df2nc(df, ncfile, prefix=\"metric_\", mode='a', units=units, standard_names=standard_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, station in stations.iterrows():\n",
    "    station.id\n",
    "    store_station(station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'l'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = names=('year', 'height', 'interpolated', 'dataflag')\n",
    "na_values = {\"height\": [-99999]}\n",
    "units = {'height': 'm'}\n",
    "standard_names = {'height': 'sea_surface_height'}\n",
    "\n",
    "filename = \"../data/psmsl/rlr_monthly/data/%d.rlrdata\" % (station.id,)\n",
    "df = pandas.read_csv(filename, sep=';', names=names, na_values=na_values)\n",
    "df.interpolated.dtype.char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def store_station(station):\n",
    "    \"\"\"\n",
    "    %   DATA FIELDS\n",
    "    %   year              Year of data\n",
    "    %   height            Annual height relative to RLR, in millimetres\n",
    "    %                       NaN indicates that data is missing\n",
    "    %   interpolated      Does the value include large amounts of\n",
    "    %                       inferred data (see PSMSL help file for information)\n",
    "    %   dataflag          Quality control flag - true values indicate problems\n",
    "    %                       with the data - see station documentation for\n",
    "    %                       further information\n",
    "    \"\"\"\n",
    "\n",
    "    df = pandas.DataFrame.from_records([station])\n",
    "    \n",
    "    df2nc(df, ncfile, attributes=station_attributes, prefix=\"\", mode='w', units=units, standard_names=standard_names)\n",
    "\n",
    "    names = names=('year', 'height', 'interpolated', 'dataflag')\n",
    "    na_values = {\"height\": [-99999]}\n",
    "    units = {'height': 'm'}\n",
    "    standard_names = {'height': 'sea_surface_height'}\n",
    "\n",
    "    filename = \"../data/psmsl/rlr_annual/data/%d.rlrdata\" % (station.id,)\n",
    "    df = pandas.read_csv(filename, sep=';', names=names, na_values=na_values)\n",
    "    df2nc(df, ncfile, prefix=\"annual_\", mode='a', units=units, standard_names=standard_names)\n",
    "\n",
    "    filename = \"../data/psmsl/rlr_monthly/data/%d.rlrdata\" % (station.id,)\n",
    "    df = pandas.read_csv(filename, sep=';', names=names, na_values=na_values)\n",
    "    df2nc(df, ncfile, prefix=\"monthly_\", mode='a', units=units, standard_names=standard_names)\n",
    "\n",
    "    filename = \"../data/psmsl/met_monthly/data/%d.metdata\" % (station.id,)\n",
    "    df = pandas.read_csv(filename, sep=';', names=names, na_values=na_values)\n",
    "    df2nc(df, ncfile, prefix=\"metric_\", mode='a', units=units, standard_names=standard_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import geojson\n",
    "import json\n",
    "features = []\n",
    "for i, station in stations.iterrows():\n",
    "    geometry = geojson.Point(coordinates=(station.longitude, station.latitude))\n",
    "    feature = geojson.Feature(\n",
    "        id=station.id, \n",
    "        geometry=geometry, \n",
    "        properties=station.to_dict()\n",
    "    )\n",
    "    features.append(feature)\n",
    "fc = geojson.FeatureCollection(features)\n",
    "with open(\"../data/psmsl/stations.json\", \"w\") as f:\n",
    "    json.dump(fc, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "geojson.feature.Feature"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, station in stations.iterrows():\n",
    "    filename = \"../data/psmsl/rlr_monthly/data/%d.rlrdata\" % (station.id,)\n",
    "    df = pandas.read_csv(filename, sep=';', names=names, na_values=na_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
